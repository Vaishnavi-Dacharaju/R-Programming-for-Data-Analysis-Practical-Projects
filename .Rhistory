train_data <- normalized_data[train_index, ]
test_data <- normalized_data[-train_index, ]
# Train a K-NN model
knn_model <- knn(train = train_data[, -6], test = test_data[, -6], cl = train_data$PersonalLoan, k = 5)
# Confusion matrix for K-NN
confusion_matrix_knn <- confusionMatrix(knn_model, test_data$PersonalLoan)
print(confusion_matrix_knn)
#Prepare data
iris2 <- iris
#Remove class attribute
iris2 <- iris[-5] #OR
iris2$Species <- NULL
Run K-means clustering for k=3
K-means clustering for k=3
View(iris_data)
View(iris2)
View(confusion_matrix_knn)
View(confusion_matrix_tree)
View(cor_matrix)
View(data)
View(iris_data)
# Load necessary libraries
library(ggplot2)
library(cluster)
library(factoextra)
# Install necessary packages if they are not already installed
if (!requireNamespace("factoextra", quietly = TRUE)) {
install.packages("factoextra")
}
if (!requireNamespace("ggplot2", quietly = TRUE)) {
install.packages("ggplot2")
}
if (!requireNamespace("cluster", quietly = TRUE)) {
install.packages("cluster")
}
# Load necessary libraries
library(ggplot2)
library(cluster)
library(factoextra)
# Load the dataset
data <- read.csv("C:/Users/vaish/Downloads/sobar-72.csv")
# Remove the class attribute
data <- subset(data, select = -ca_cervix)
# Handle missing values (if any)
data <- na.omit(data)
# Scale the data
scaled_data <- scale(data)
# Determine the optimal number of clusters using the Elbow method
fviz_nbclust(scaled_data, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2) +
labs(subtitle = "Elbow method")
# Set seed for reproducibility
set.seed(123)
# Apply K-Means clustering with the optimal number of clusters (e.g., 3)
kmeans_result <- kmeans(scaled_data, centers = 3, nstart = 25)
View(kmeans_result)
View(kmeans_result)
View(kmeans_result)
# Add cluster assignments to the original data
data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters using PCA
fviz_cluster(kmeans_result, data = scaled_data, geom = "point", ellipse.type = "norm") +
labs(title = "K-Means Clustering", x = "Principal Component 1", y = "Principal Component 2")
# Visualize the clusters using PCA
fviz_cluster(kmeans_result, data = scaled_data, geom = "point", ellipse.type = "norm") +
labs(title = "K-Means Clustering", x = "Principal Component 1", y = "Principal Component 1")
# Print cluster centers
print(kmeans_result$centers)
# Evaluate clustering
clusplot(data, kmeans_result$cluster, color = TRUE, shade = TRUE, labels = 2, lines = 0)
View(kmeans_result)
# Install necessary packages
install.packages("caTools")
install.packages("arules")
install.packages("rpart")
install.packages("tm")
install.packages("wordcloud")
# Load necessary packages
library(caTools)
library(arules)
library(rpart)
library(tm)
library(wordcloud)
library(e1071)
library(caret)
library(ggplot2)
library(dplyr)
library(factoextra)
# Load the data
student_data <- read.csv("C:/Users/vaish/OneDrive/Desktop/student-por.csv")
# Install necessary packages
install.packages("caTools")
install.packages("arules")
install.packages("rpart")
install.packages("tm")
# Load necessary packages
library(caTools)
library(arules)
library(rpart)
library(tm)
library(wordcloud)
library(e1071)
library(caret)
library(ggplot2)
library(dplyr)
library(factoextra)
# Load the data
student_data <- read.csv("C:/Users/vaish/OneDrive/Desktop/student-por.csv")
# Dealing with Missing Data
FixNull <- function(attribute) {
ifelse(is.na(attribute), mean(attribute, na.rm = TRUE), attribute)
}
student_data$famsize <- FixNull(student_data$famsize)
student_data$Medu <- FixNull(student_data$Medu)
# Dealing with Categorical Variables
student_data <- student_data %>%
mutate(across(where(is.character), as.factor))
# Splitting the Model
set.seed(12345)
sp <- sample.split(student_data$sex, SplitRatio = 0.6)
trainingSet <- subset(student_data, sp == TRUE)
testSet <- subset(student_data, sp == FALSE)
# Feature Scaling
trainingSet[, c(3, 14)] <- scale(trainingSet[, c(3, 14)])
testSet[, c(3, 14)] <- scale(testSet[, c(3, 14)])
# Data Visualization
# Box Plot: Study time by number of failures
ggplot(student_data, aes(x = factor(failures), y = studytime)) +
geom_boxplot() +
labs(title = "Box Plot of Study Time by Number of Failures", x = "Number of Failures", y = "Study Time")
# Histogram: Distribution of Free Time
ggplot(student_data, aes(x = freetime)) +
geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
labs(title = "Histogram of Free Time", x = "Free Time", y = "Frequency")
# Scatter Plot: Age vs Study Time
ggplot(student_data, aes(x = age, y = studytime)) +
geom_point(color = "blue", alpha = 0.5) +
labs(title = "Scatter Plot of Age vs Study Time", x = "Age", y = "Study Time")
# Bar Plot: Counts of Family Size
ggplot(student_data, aes(x = famsize)) +
geom_bar(fill = "coral", color = "black") +
labs(title = "Bar Plot of Family Size", x = "Family Size", y = "Count")
# Density Plot: Distribution of Age
ggplot(student_data, aes(x = age, fill = sex)) +
geom_density(alpha = 0.5) +
labs(title = "Density Plot of Age Distribution by Sex", x = "Age", y = "Density")
# Association Analysis using Apriori Algorithm
itemset <- as(trainingSet[, c(3, 14)], "transactions")
# Perform Apriori analysis
rules <- apriori(itemset, parameter = list(support = 0.1, confidence = 0.7))
# Decision Tree Classification
tree_model <- rpart(famsize ~ ., data = trainingSet)
# Make predictions on the test set
predictions <- predict(tree_model, testSet, type = "class")
# Confusion Matrix
conf_matrix <- confusionMatrix(predictions, testSet$famsize)
print(conf_matrix)
# Naive Bayes Classification
target_variable <- "famsize"
predictor_variables <- setdiff(names(trainingSet), target_variable)
# Train the Naive Bayes model
nb_model <- naiveBayes(as.formula(paste(target_variable, "~", paste(predictor_variables, collapse = " + "))), data = trainingSet)
# Make predictions on the test set
nb_predictions <- predict(nb_model, testSet, type = "class")
# Generate the confusion matrix
confusion_matrix <- confusionMatrix(nb_predictions, testSet$famsize)
print(confusion_matrix)
# Text Mining
corpus <- Corpus(VectorSource(student_data$Fjob))
# Perform text cleaning
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
# Find the top 10 terms in the corpus
term_freq <- DocumentTermMatrix(corpus)
term_freq_matrix <- as.matrix(term_freq)
term_freq_df <- data.frame(word = colnames(term_freq_matrix), freq = colSums(term_freq_matrix))
top_10_terms <- head(term_freq_df[order(term_freq_df$freq, decreasing = TRUE), ], 10)
# Display a word cloud for top words
wordcloud(words = top_10_terms$word, freq = top_10_terms$freq, min.freq = 1, scale = c(3, 0.2), colors = brewer.pal(8, "Dark2"))
# Plot word frequencies for top words
barplot(top_10_terms$freq, names.arg = top_10_terms$word, col = "skyblue", main = "Top 10 Words Frequency", xlab = "Word", ylab = "Frequency")
# Clustering Analysis
# Preprocess the data for clustering
clustering_data <- student_data %>%
select(age, studytime, freetime, absences, G1, G2, G3) %>%
scale()
View(clustering_data)
View(clustering_data)
# Determine the optimal number of clusters using the Elbow method
fviz_nbclust(clustering_data, kmeans, method = "wss")
# Perform k-means clustering with the chosen number of clusters (e.g., 3)
set.seed(123)
k <- 3
kmeans_result <- kmeans(clustering_data, centers = k, nstart = 25)
# Add the cluster assignments to the original dataset
student_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clustering results
# Scatter plot of Age vs Study Time colored by clusters
ggplot(student_data, aes(x = age, y = studytime, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering: Age vs Study Time", x = "Age", y = "Study Time")
# Scatter plot of G1 vs G3 colored by clusters
ggplot(student_data, aes(x = G1, y = G3, color = cluster)) +
geom_point() +
labs(title = "K-means Clustering: G1 vs G3", x = "G1 Grade", y = "G3 Grade")
# Summary of clusters
summary(kmeans_result)
# Install necessary packages
install.packages("caTools")
install.packages("arules")
install.packages("rpart")
install.packages("tm")
install.packages("wordcloud")
install.packages("e1071")
# Load necessary packages
library(caTools)
library(arules)
library(rpart)
library(tm)
library(wordcloud)
library(e1071)
library(caret)
library(ggplot2)
library(dplyr)
library(factoextra)
# Load the data
student_data <- read.csv("C:/Users/vaish/OneDrive/Desktop/student-por.csv")
# Dealing with Missing Data
FixNull <- function(attribute) {
ifelse(is.na(attribute), mean(attribute, na.rm = TRUE), attribute)
# Dealing with Missing Data
FixNull <- function(attribute) {
ifelse(is.na(attribute), mean(attribute, na.rm = TRUE), attribute)
}
student_data$famsize <- FixNull(student_data$famsize)
student_data$Medu <- FixNull(student_data$Medu)
# Dealing with Categorical Variables
student_data <- student_data %>%
mutate(across(where(is.character), as.factor))
# Install necessary packages
install.packages("caTools")
install.packages("arules")
install.packages("rpart")
install.packages("tm")
install.packages("wordcloud")
install.packages("e1071")
install.packages("caret")
install.packages("ggplot2")
install.packages("dplyr")
install.packages("factoextra")
# Load necessary packages
library(caTools)
library(arules)
library(rpart)
library(tm)
library(wordcloud)
library(e1071)
library(caret)
library(ggplot2)
library(dplyr)
library(factoextra)
# Load the data
student_data <- read.csv("C:/Users/vaish/OneDrive/Desktop/student-por.csv")
# Dealing with Missing Data
FixNull <- function(attribute) {
ifelse(is.na(attribute), mean(attribute, na.rm = TRUE), attribute)
}
student_data$famsize <- FixNull(student_data$famsize)
student_data$Medu <- FixNull(student_data$Medu)
# Dealing with Categorical Variables
student_data <- student_data %>%
mutate(across(where(is.character), as.factor))
# Splitting the Model
set.seed(12345)
sp <- sample.split(student_data$sex, SplitRatio = 0.6)
trainingSet <- subset(student_data, sp == TRUE)
testSet <- subset(student_data, sp == FALSE)
# Feature Scaling
trainingSet[, c(3, 14)] <- scale(trainingSet[, c(3, 14)])
testSet[, c(3, 14)] <- scale(testSet[, c(3, 14)])
# Data Visualization
# Box Plot: Study time by number of failures
ggplot(student_data, aes(x = factor(failures), y = studytime)) +
geom_boxplot() +
labs(title = "Box Plot of Study Time by Number of Failures", x = "Number of Failures", y = "Study Time")
# Load the libraries
library(tm)
library(SnowballC)
library(cluster)
library(wordcloud)
# Load the dataset
data("crude")
# Text preprocessing
corpus <- tm_map(crude, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
# Create document-term matrix
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.95)
# Convert to matrix
dtm_matrix <- as.matrix(dtm)
# K-means clustering
set.seed(123)
k <- 2  # Number of clusters
kmeans_result <- kmeans(dtm_matrix, centers=k)
# Print results
print(kmeans_result$cluster)
print(table(kmeans_result$cluster))
# Hierarchical clustering
dist_matrix <- dist(dtm_matrix)
hc_result <- hclust(dist_matrix, method="ward.D")
# Plot dendrogram
plot(hc_result)
rect.hclust(hc_result, k=2, border="red")
# K-means clustering
set.seed(123)
k <- 2  # Number of clusters
kmeans_result <- kmeans(dtm_matrix, centers=k)
# Print results
print(kmeans_result$cluster)
print(table(kmeans_result$cluster))
install.packages(c("dplyr", "ggplot2"))
library(dplyr)
library(ggplot2)
# Load dataset using your file path
data <- read.csv("C:/Users/vaish/OneDrive/Desktop/Online Retail.csv")
# Calculate total sales for each product description
data$Total_Sales <- data$Quantity * data$UnitPrice
total_sales_by_product <- data %>%
group_by(Description) %>%
summarize(Total_Sales = sum(Total_Sales, na.rm = TRUE)) %>%
arrange(desc(Total_Sales))
# Print the top 10 products by sales
print(head(total_sales_by_product, 10))
# Create a pie chart of total sales by product description (top 10)
top_10_products <- head(total_sales_by_product, 10)
ggplot(top_10_products, aes(x = "", y = Total_Sales, fill = Description)) +
geom_bar(stat = "identity", width = 1) +
coord_polar("y") +
labs(title = "Total Sales by Product Description (Top 10)", x = "", y = "") +
theme_void()
# Convert InvoiceDate to Date format
data$InvoiceDate <- as.POSIXct(data$InvoiceDate, format="%Y-%m-%d %H:%M:%S")
# Extract Year and Month for grouping
data$YearMonth <- format(data$InvoiceDate, "%Y-%m")
# Calculate monthly sales
monthly_sales <- data %>%
group_by(YearMonth) %>%
summarize(Total_Sales = sum(Total_Sales, na.rm = TRUE))
# Plot the monthly sales trends
ggplot(monthly_sales, aes(x = YearMonth, y = Total_Sales, group = 1)) +
geom_line(color = "blue") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Monthly Sales Trends", x = "Month", y = "Total Sales")
# Group data by country to see distribution of customers and sales
customer_distribution <- data %>%
group_by(Country) %>%
summarize(Customer_Count = n_distinct(CustomerID),
Total_Sales = sum(Total_Sales, na.rm = TRUE)) %>%
arrange(desc(Total_Sales))
# Print the customer distribution
print(customer_distribution)
# Create a bar plot for the customer purchase distribution by country
ggplot(customer_distribution, aes(x = reorder(Country, -Total_Sales), y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Customer Purchase Distribution by Country", x = "Country", y = "Total Sales")
# Group data by country to see distribution of customers and sales
customer_distribution <- data %>%
group_by(Country) %>%
summarize(Customer_Count = n_distinct(CustomerID),
Total_Sales = sum(Total_Sales, na.rm = TRUE)) %>%
arrange(desc(Total_Sales))
# Print the customer distribution
print(customer_distribution)
# Create a bar plot for the customer purchase distribution by country
ggplot(customer_distribution, aes(x = reorder(Country, -Total_Sales), y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Customer Purchase Distribution by Country", x = "Country", y = "Total Sales")
# Similar to the first pie chart but explicitly for visualization purposes
ggplot(top_10_products, aes(x = "", y = Total_Sales, fill = Description)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y") +
labs(title = "Sales by Product Description (Top 10 Products)", x = "", y = "") +
theme_void()
library(ggplot2)
library(dplyr)
library(scales)
# Assuming the dataset is loaded as 'sales_data'
# sales_data <- read.csv("Online Retail.csv")
# Convert InvoiceDate to Date format and extract Year, Quarter, and Month
sales_data$InvoiceDate <- as.Date(sales_data$InvoiceDate, format="%Y-%m-%d %H:%M:%S")
# Load required packages
library(ggplot2)
library(dplyr)
library(scales)
library(gridExtra)
# Load the dataset from your local path
sales_data <- read.csv("C:/Users/vaish/OneDrive/Desktop/Online Retail.csv")
# Convert InvoiceDate to Date format
sales_data$InvoiceDate <- as.Date(sales_data$InvoiceDate, format="%Y-%m-%d %H:%M:%S")
library(gridExtra)
# Total Sales KPI
total_sales <- sales_data %>%
summarise(TotalSales = sum(Quantity * UnitPrice))
# Unique Customers KPI
unique_customers <- sales_data %>%
summarise(UniqueCustomers = n_distinct(CustomerID))
# Average Order Value (AOV) KPI
aov <- total_sales$TotalSales / nrow(sales_data)
# Sales by Region (Top 5 countries)
sales_by_country <- sales_data %>%
group_by(Country) %>%
summarise(TotalSales = sum(Quantity * UnitPrice)) %>%
arrange(desc(TotalSales)) %>%
head(5)
# KPI Visualizations
kpi_sales <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Total Sales:\n$", round(total_sales$TotalSales, 2))),
size=8, color="blue") +
theme_void()
kpi_customers <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Unique Customers:\n", unique_customers$UniqueCustomers)),
size=8, color="green") +
theme_void()
kpi_aov <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Avg Order Value:\n$", round(aov, 2))),
size=8, color="purple") +
theme_void()
# Sales by Country Bar Chart
sales_by_country_plot <- ggplot(sales_by_country, aes(x = reorder(Country, TotalSales), y = TotalSales)) +
geom_bar(stat = "identity", fill = "orange") +
coord_flip() +
labs(title = "Top 5 Countries by Sales",
x = "Country",
y = "Total Sales (in $)") +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Combine KPIs and Sales by Country
grid.arrange(kpi_sales, kpi_customers, kpi_aov, sales_by_country_plot, nrow = 2, ncol = 2)
# Calculate total sales and average price of top 10 products by revenue
top_products <- sales_data %>%
group_by(StockCode, Description) %>%
summarise(TotalSales = sum(Quantity * UnitPrice),
AveragePrice = mean(UnitPrice),
TotalQuantity = sum(Quantity)) %>%
arrange(desc(TotalSales)) %>%
head(10)
# Bar Chart: Top 10 Products by Sales
ggplot(top_products, aes(x = reorder(Description, TotalSales), y = TotalSales)) +
geom_bar(stat = "identity", fill = "green") +
coord_flip() +
labs(title = "Top 10 Products by Total Sales",
x = "Product",
y = "Total Sales (in $)") +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Scatter Plot: Average Price vs. Total Sales of Top Products
ggplot(top_products, aes(x = AveragePrice, y = TotalSales)) +
geom_point(aes(size = TotalQuantity, color = Description), alpha = 0.7) +
labs(title = "Average Price vs. Total Sales of Top Products",
x = "Average Price (in $)",
y = "Total Sales (in $)") +
scale_y_continuous(labels = scales::dollar) +
scale_x_continuous(labels = scales::dollar) +
theme_minimal() +
theme(legend.position = "none")
library(gridExtra)
# Total Sales KPI
total_sales <- sales_data %>%
summarise(TotalSales = sum(Quantity * UnitPrice))
# Unique Customers KPI
unique_customers <- sales_data %>%
summarise(UniqueCustomers = n_distinct(CustomerID))
# Average Order Value (AOV) KPI
aov <- total_sales$TotalSales / nrow(sales_data)
# Sales by Region (Top 5 countries)
sales_by_country <- sales_data %>%
group_by(Country) %>%
summarise(TotalSales = sum(Quantity * UnitPrice)) %>%
arrange(desc(TotalSales)) %>%
head(5)
# KPI Visualizations
kpi_sales <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Total Sales:\n$", round(total_sales$TotalSales, 2))),
size=8, color="blue") +
theme_void()
kpi_customers <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Unique Customers:\n", unique_customers$UniqueCustomers)),
size=8, color="green") +
theme_void()
kpi_aov <- ggplot() +
geom_text(aes(x=1, y=1, label=paste("Avg Order Value:\n$", round(aov, 2))),
size=8, color="purple") +
theme_void()
# Sales by Country Bar Chart
sales_by_country_plot <- ggplot(sales_by_country, aes(x = reorder(Country, TotalSales), y = TotalSales)) +
geom_bar(stat = "identity", fill = "orange") +
coord_flip() +
labs(title = "Top 5 Countries by Sales",
x = "Country",
y = "Total Sales (in $)") +
scale_y_continuous(labels = scales::dollar) +
theme_minimal()
# Combine KPIs and Sales by Country
grid.arrange(kpi_sales, kpi_customers, kpi_aov, sales_by_country_plot, nrow = 2, ncol = 2)
